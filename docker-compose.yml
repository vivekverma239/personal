version: "3.3"
services:
  backend:
    build: backend
    container_name: backend
    restart: always
    depends_on:
      - tf-serving
    expose:
      - 8000
    environment:
      ENV: prod
    command: bash -c "python3 manage.py collectstatic -c --no-input && gunicorn --workers=3 experiments.wsgi -b 0.0.0.0:8000"
  nginx:
    image: nginx:latest
    container_name: nginx
    restart: always
    depends_on:
      - tf-serving
      - backend
    expose:
      - 80
      - 443
    ports:
      - 80:80
      - 443:443
    volumes:
      - /home/ec2-user/personal/nginx/nginx.conf:/etc/nginx/nginx.conf
      - /home/ec2-user/personal/ssl:/ssl/
  tf-serving:
    container_name: tf-serving
    restart: always
    image: tensorflow/serving:latest
    expose:
      - 8500
      - 8501
    ports:
      - 8501:8501
      - 8500:8500
    volumes:
      - "./data/serving_models/:/models/"
    command: --model_config_file=/models/models.config --model_config_file_poll_wait_seconds=60
networks:
  default:
    name: docker-net
    driver: bridge
